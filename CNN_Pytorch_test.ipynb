{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Thesis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to load configurations\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as file:\n",
    "        config = json.load(file)\n",
    "    return config\n",
    "\n",
    "# Load the configuration\n",
    "config = load_config('config/config.json')\n",
    "\n",
    "# Access the dataset path\n",
    "dataset_dir = config['dataset_path']\n",
    "train_dir = config['train_path']\n",
    "val_dir = config['val_path']\n",
    "test_dir = config['test_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, dropout_rate):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),  # Assume RGB images\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(32 * 16 * 16, 512),  # Flatten size depends on input image size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)  # Adjust based on the number of classes in your dataset\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for Optuna to optimize\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    lr = trial.suggest_loguniform('lr', 1e-4, 1e-1)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "\n",
    "    # Transformations and data loading\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),  # Resize images to 64x64\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "    val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyCNN(dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(10):  # Reduced epochs for demonstration\n",
    "        model.train()\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item(  accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 00:31:30,710] A new study created in memory with name: no-name-a822bf4a-4f37-42da-a3ef-d536383af0e0\n",
      "/var/folders/_0/n_t3__qd6k15bv63l5bktb8m0000gn/T/ipykernel_86418/288307961.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-1)\n",
      "[I 2024-11-01 00:32:18,345] Trial 0 finished with value: 0.5714285714285714 and parameters: {'dropout_rate': 0.4070816891051241, 'lr': 0.021073229223398205, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:33:07,444] Trial 1 finished with value: 0.5357142857142857 and parameters: {'dropout_rate': 0.26693458078077825, 'lr': 0.0006268491965006621, 'batch_size': 16}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:33:57,302] Trial 2 finished with value: 0.5 and parameters: {'dropout_rate': 0.20317701458218007, 'lr': 0.0010789161407712292, 'batch_size': 16}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:34:45,748] Trial 3 finished with value: 0.5 and parameters: {'dropout_rate': 0.44520750946862386, 'lr': 0.00020908562010054716, 'batch_size': 64}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:35:36,480] Trial 4 finished with value: 0.42857142857142855 and parameters: {'dropout_rate': 0.2823229047557646, 'lr': 0.038503613036389606, 'batch_size': 64}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:36:23,623] Trial 5 finished with value: 0.5714285714285714 and parameters: {'dropout_rate': 0.18383669523447482, 'lr': 0.0029738057880361675, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:37:10,107] Trial 6 finished with value: 0.5714285714285714 and parameters: {'dropout_rate': 0.16259772609443485, 'lr': 0.00987311519535367, 'batch_size': 64}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:37:57,476] Trial 7 finished with value: 0.42857142857142855 and parameters: {'dropout_rate': 0.3692807575940181, 'lr': 0.07600042568499946, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:38:46,068] Trial 8 finished with value: 0.5 and parameters: {'dropout_rate': 0.11237580561106655, 'lr': 0.00032433203312034315, 'batch_size': 16}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:39:32,406] Trial 9 finished with value: 0.5 and parameters: {'dropout_rate': 0.4194140223812427, 'lr': 0.0016137813270903497, 'batch_size': 64}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:40:19,551] Trial 10 finished with value: 0.5714285714285714 and parameters: {'dropout_rate': 0.476640235441337, 'lr': 0.01228696799542626, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:41:06,798] Trial 11 finished with value: 0.42857142857142855 and parameters: {'dropout_rate': 0.36615862346617073, 'lr': 0.006564578762612899, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:41:54,106] Trial 12 finished with value: 0.42857142857142855 and parameters: {'dropout_rate': 0.2078767316772147, 'lr': 0.0031958734699130678, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:42:41,491] Trial 13 finished with value: 0.42857142857142855 and parameters: {'dropout_rate': 0.33722137342440583, 'lr': 0.02396180115754788, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:43:29,975] Trial 14 finished with value: 0.39285714285714285 and parameters: {'dropout_rate': 0.2450578049049022, 'lr': 0.003736270809150168, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:44:17,788] Trial 15 finished with value: 0.42857142857142855 and parameters: {'dropout_rate': 0.12151746517376287, 'lr': 0.08044003809270622, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:45:06,624] Trial 16 finished with value: 0.42857142857142855 and parameters: {'dropout_rate': 0.30993520755582404, 'lr': 0.01860117995751594, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:45:54,151] Trial 17 finished with value: 0.42857142857142855 and parameters: {'dropout_rate': 0.41898771210852515, 'lr': 0.0048802107135427, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:46:41,748] Trial 18 finished with value: 0.35714285714285715 and parameters: {'dropout_rate': 0.4855933758497571, 'lr': 0.0017128198032552008, 'batch_size': 32}. Best is trial 0 with value: 0.5714285714285714.\n",
      "[I 2024-11-01 00:47:30,744] Trial 19 finished with value: 0.42857142857142855 and parameters: {'dropout_rate': 0.21919276358114936, 'lr': 0.037134018314693186, 'batch_size': 16}. Best is trial 0 with value: 0.5714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'dropout_rate': 0.4070816891051241, 'lr': 0.021073229223398205, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "# Creating the Optuna study and running optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)  # You can increase or decrease the number of trials\n",
    "\n",
    "print('Best hyperparameters:', study.best_trial.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
