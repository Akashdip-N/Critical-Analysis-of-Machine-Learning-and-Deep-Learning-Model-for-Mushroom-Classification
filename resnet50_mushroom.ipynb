{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, precision_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to load configurations\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as file:\n",
    "        config = json.load(file)\n",
    "    return config\n",
    "\n",
    "# Load the configuration\n",
    "config = load_config('config/config.json')\n",
    "\n",
    "# Access the dataset path\n",
    "dataset_dir = config['dataset_path']\n",
    "train_dir = config['train_path']\n",
    "val_dir = config['val_path']\n",
    "test_dir = config['test_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize all images to 64x64\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and validation data\n",
    "train_data = ImageFolder(root=train_dir, transform=transform)\n",
    "trainloader = DataLoader(train_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = ImageFolder(root=val_dir, transform=transform)\n",
    "valloader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the ResNet model\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_classes = len(train_data.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store metrics\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'val_loss': [],\n",
    "    'val_accuracy': [],\n",
    "    'val_precision': []  # Ensure you add functionality to calculate precision if needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 0.7180, Accuracy: 46.39%, Loss: 0.8024, Val Accuracy: 42.86%, Validation Precision: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Train Loss: 0.6518, Accuracy: 62.37%, Loss: 0.7715, Val Accuracy: 42.86%, Validation Precision: 0.2143\n",
      "Epoch 3/30\n",
      "Train Loss: 0.5841, Accuracy: 78.35%, Loss: 0.7327, Val Accuracy: 35.71%, Validation Precision: 0.1923\n",
      "Epoch 4/30\n",
      "Train Loss: 0.5282, Accuracy: 82.99%, Loss: 0.6980, Val Accuracy: 46.43%, Validation Precision: 0.5174\n",
      "Epoch 5/30\n",
      "Train Loss: 0.4077, Accuracy: 89.69%, Loss: 0.8991, Val Accuracy: 46.43%, Validation Precision: 0.7222\n",
      "Epoch 6/30\n",
      "Train Loss: 0.3006, Accuracy: 91.75%, Loss: 0.6328, Val Accuracy: 64.29%, Validation Precision: 0.6429\n",
      "Epoch 7/30\n",
      "Train Loss: 0.2072, Accuracy: 97.42%, Loss: 0.6314, Val Accuracy: 67.86%, Validation Precision: 0.6744\n",
      "Epoch 8/30\n",
      "Train Loss: 0.1636, Accuracy: 98.97%, Loss: 0.6061, Val Accuracy: 71.43%, Validation Precision: 0.7111\n",
      "Epoch 9/30\n",
      "Train Loss: 0.1004, Accuracy: 98.45%, Loss: 0.8324, Val Accuracy: 57.14%, Validation Precision: 0.6250\n",
      "Epoch 10/30\n",
      "Train Loss: 0.0592, Accuracy: 98.97%, Loss: 0.7460, Val Accuracy: 57.14%, Validation Precision: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "Train Loss: 0.0955, Accuracy: 98.45%, Loss: 0.7960, Val Accuracy: 57.14%, Validation Precision: 0.2857\n",
      "Epoch 12/30\n",
      "Train Loss: 0.0673, Accuracy: 100.00%, Loss: 0.6566, Val Accuracy: 71.43%, Validation Precision: 0.7292\n",
      "Epoch 13/30\n",
      "Train Loss: 0.0408, Accuracy: 100.00%, Loss: 0.7647, Val Accuracy: 67.86%, Validation Precision: 0.7032\n",
      "Epoch 14/30\n",
      "Train Loss: 0.0150, Accuracy: 100.00%, Loss: 0.8365, Val Accuracy: 71.43%, Validation Precision: 0.7292\n",
      "Epoch 15/30\n",
      "Train Loss: 0.0230, Accuracy: 100.00%, Loss: 0.8839, Val Accuracy: 60.71%, Validation Precision: 0.6128\n",
      "Epoch 16/30\n",
      "Train Loss: 0.1225, Accuracy: 94.33%, Loss: 0.6542, Val Accuracy: 53.57%, Validation Precision: 0.5702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "Train Loss: 0.4931, Accuracy: 75.26%, Loss: 0.7407, Val Accuracy: 57.14%, Validation Precision: 0.2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Thesis/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "Train Loss: 0.4688, Accuracy: 81.44%, Loss: 0.9927, Val Accuracy: 42.86%, Validation Precision: 0.2143\n",
      "Epoch 19/30\n",
      "Train Loss: 0.2056, Accuracy: 94.85%, Loss: 0.6713, Val Accuracy: 60.71%, Validation Precision: 0.6283\n",
      "Epoch 20/30\n",
      "Train Loss: 0.0888, Accuracy: 100.00%, Loss: 0.8710, Val Accuracy: 53.57%, Validation Precision: 0.5535\n",
      "Epoch 21/30\n",
      "Train Loss: 0.0644, Accuracy: 100.00%, Loss: 1.1788, Val Accuracy: 64.29%, Validation Precision: 0.7727\n",
      "Epoch 22/30\n",
      "Train Loss: 0.0489, Accuracy: 98.97%, Loss: 1.6337, Val Accuracy: 64.29%, Validation Precision: 0.7727\n",
      "Epoch 23/30\n",
      "Train Loss: 0.0509, Accuracy: 98.45%, Loss: 1.0515, Val Accuracy: 64.29%, Validation Precision: 0.6562\n",
      "Epoch 24/30\n",
      "Train Loss: 0.0221, Accuracy: 99.48%, Loss: 1.2367, Val Accuracy: 60.71%, Validation Precision: 0.6283\n",
      "Epoch 25/30\n",
      "Train Loss: 0.2980, Accuracy: 88.66%, Loss: 2.0854, Val Accuracy: 46.43%, Validation Precision: 0.7222\n",
      "Epoch 26/30\n",
      "Train Loss: 0.1667, Accuracy: 94.85%, Loss: 1.8340, Val Accuracy: 53.57%, Validation Precision: 0.7400\n",
      "Epoch 27/30\n",
      "Train Loss: 0.0619, Accuracy: 97.94%, Loss: 1.0825, Val Accuracy: 60.71%, Validation Precision: 0.6905\n",
      "Epoch 28/30\n",
      "Train Loss: 0.0271, Accuracy: 100.00%, Loss: 1.0008, Val Accuracy: 71.43%, Validation Precision: 0.7556\n",
      "Epoch 29/30\n",
      "Train Loss: 0.0495, Accuracy: 98.45%, Loss: 1.1622, Val Accuracy: 67.86%, Validation Precision: 0.7339\n",
      "Epoch 30/30\n",
      "Train Loss: 0.3449, Accuracy: 87.11%, Loss: 1.3719, Val Accuracy: 60.71%, Validation Precision: 0.6905\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(number_of_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    epoch_train_loss = running_loss / total_train\n",
    "    epoch_train_accuracy = 100 * correct_train / total_train\n",
    "    history['train_loss'].append(epoch_train_loss)\n",
    "    history['train_accuracy'].append(epoch_train_accuracy)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss = val_running_loss / total_val\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_accuracy)\n",
    "    history['val_precision'].append(val_precision)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{number_of_epochs}')\n",
    "    print(f'Train Loss: {epoch_train_loss:.4f}, Accuracy: {epoch_train_accuracy:.2f}%, Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, Validation Precision: {val_precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'Pth_Files/Resnet50_model_{number_of_epochs}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the model\n",
    "def load_model(file_name = f'Pth_Files/Resnet50_model_{number_of_epochs}.pth'):\n",
    "    model = models.resnet50(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(file_name))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Function to preprocess and predict a new image\n",
    "def predict_image(model, image_path):\n",
    "    image = Image.open(image_path)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_class = train_data.classes[predicted[0]]\n",
    "        \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = test_dir + \"/edible/Agaricus_abruptibulbus/Agaricus_abruptibulbus_1.jpg\"\n",
    "image_2 = test_dir + \"/poisonous/Amanita_excelsa/Amanita_excelsa_1.jpg\"\n",
    "image_3 = test_dir + \"/edible/Agaricus_abruptibulbus/Agaricus_abruptibulbus_2.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The imag_1 is predicted as class: edible\n",
      "The imag_2 is predicted as class: edible\n",
      "The imag_3 is predicted as class: edible\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "print(f'The imag_1 is predicted as class: {predict_image(load_model(), image_1)}')\n",
    "print(f'The imag_2 is predicted as class: {predict_image(load_model(), image_2)}')\n",
    "print(f'The imag_3 is predicted as class: {predict_image(load_model(), image_3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot training & validation accuracy values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "acc = history['train_accuracy']\n",
    "val_acc = history['val_accuracy']\n",
    "loss = history['train_loss']\n",
    "val_loss = history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score    support\n",
      "Class 0        0.523810  0.916667  0.666667  12.000000\n",
      "Class 1        0.857143  0.375000  0.521739  16.000000\n",
      "accuracy       0.607143  0.607143  0.607143   0.607143\n",
      "macro avg      0.690476  0.645833  0.594203  28.000000\n",
      "weighted avg   0.714286  0.607143  0.583851  28.000000\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(all_labels, all_preds, target_names=['Class 0', 'Class 1'], output_dict=True)\n",
    "df_cr = pd.DataFrame(cr).transpose()\n",
    "\n",
    "print(df_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.title('Confusion Matrix Resnet50 Model')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
